{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils import to_categorical\n",
    "from cleverhans.utils import set_log_level\n",
    "from cleverhans.utils_tf import model_train, model_eval, batch_eval\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.attacks_tf import jacobian_graph, jacobian_augmentation\n",
    "\n",
    "from cleverhans_tutorials.tutorial_models import make_basic_cnn, MLP\n",
    "from cleverhans_tutorials.tutorial_models import Flatten, Linear, ReLU, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General setup\n",
    "set_log_level(logging.DEBUG)\n",
    "rng = np.random.RandomState([2017, 8, 30])\n",
    "accuracies = {}\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "sess = tf.Session()\n",
    "x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "X_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Setup dataset\n",
    "train_start, train_end = 0, 60000\n",
    "test_start, test_end = 0, 10000\n",
    "holdout = 150\n",
    "\n",
    "# Get MNIST data\n",
    "X_train, Y_train, X_test, Y_test = data_mnist(train_start=train_start,\n",
    "                                              train_end=train_end,\n",
    "                                              test_start=test_start,\n",
    "                                              test_end=test_end)\n",
    "\n",
    "# Initialize substitute training set reserved for adversary\n",
    "X_sub = X_test[:holdout]\n",
    "Y_sub = np.argmax(Y_test[:holdout], axis=1)\n",
    "\n",
    "# Redefine test set as remaining samples unavailable to adversaries\n",
    "X_test = X_test[holdout:]\n",
    "Y_test = Y_test[holdout:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined TensorFlow model graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/src/cleverhans/cleverhans/utils_tf.py:114: UserWarning: verbose argument is deprecated and will be removed on 2018-02-11. Instead, use utils.set_log_level(). For backward compatibility, log_level was set to logging.WARNING (30).\n",
      "  warnings.warn(\"verbose argument is deprecated and will be removed\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of black-box on legitimate test examples: 0.98923857868\n"
     ]
    }
   ],
   "source": [
    "# Train our own \"black-box\"\n",
    "n_blackbox_epochs = n_epochs\n",
    "n_blackbox_batch_size = batch_size\n",
    "blackbox_learning_rate = learning_rate\n",
    "\n",
    "model = make_basic_cnn()\n",
    "bbox_preds = model(x)\n",
    "print(\"Defined TensorFlow model graph.\")\n",
    "\n",
    "# Train an MNIST model\n",
    "train_params = {\n",
    "    'nb_epochs': n_blackbox_epochs,\n",
    "    'batch_size': n_blackbox_batch_size,\n",
    "    'learning_rate': blackbox_learning_rate\n",
    "}\n",
    "model_train(sess, x, y, bbox_preds, X_train, Y_train, verbose=False,\n",
    "            args=train_params, rng=rng)\n",
    "\n",
    "# Print out the accuracy on legitimate data\n",
    "eval_params = {'batch_size': n_blackbox_batch_size}\n",
    "accuracies['bbox'] = model_eval(sess, x, y, bbox_preds, X_test, Y_test, args=eval_params)\n",
    "print('Test accuracy of black-box on legitimate test '\n",
    "      'examples: ' + str(accuracies['bbox']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute training epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/src/cleverhans/cleverhans/utils_tf.py:114: UserWarning: verbose argument is deprecated and will be removed on 2018-02-11. Instead, use utils.set_log_level(). For backward compatibility, log_level was set to logging.WARNING (30).\n",
      "  warnings.warn(\"verbose argument is deprecated and will be removed\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #1\n",
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #2\n",
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #3\n",
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #4\n",
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #5\n"
     ]
    }
   ],
   "source": [
    "# Train the substitute model using a new set of data with jacobian augmentation (this sounds fancy because it's part of their methodology)\n",
    "n_blackbox_classes = 10\n",
    "data_aug = 6\n",
    "sub_epochs = 10\n",
    "sub_batch_size = batch_size\n",
    "sub_learning_rate = learning_rate\n",
    "sub_lmbda = 0.1\n",
    "\n",
    "# Define a fully connected model (it's different than the black-box)\n",
    "img_rows, img_cols = 28, 28\n",
    "layers = [Flatten(),\n",
    "          Linear(200),\n",
    "          ReLU(),\n",
    "          Linear(200),\n",
    "          ReLU(),\n",
    "          Linear(n_blackbox_classes),\n",
    "          Softmax()]\n",
    "input_shape = (None, img_rows, img_cols, 1)\n",
    "model_sub =  MLP(layers, input_shape)\n",
    "\n",
    "# Define TF model graph (for the black-box model)\n",
    "preds_sub = model_sub(x)\n",
    "\n",
    "# Define the Jacobian symbolically using TensorFlow\n",
    "grads = jacobian_graph(preds_sub, x, n_blackbox_classes)\n",
    "\n",
    "# Train the substitute and augment dataset alternatively\n",
    "for rho in xrange(data_aug):\n",
    "    print(\"Substitute training epoch #\" + str(rho))\n",
    "    train_params = {\n",
    "        'nb_epochs': sub_epochs,\n",
    "        'batch_size': sub_batch_size,\n",
    "        'learning_rate': sub_learning_rate\n",
    "    }\n",
    "    model_train(sess, x, y, preds_sub, X_sub, to_categorical(Y_sub),\n",
    "                init_all=False, verbose=False, args=train_params,\n",
    "                rng=rng)\n",
    "\n",
    "    # If we are not at last substitute training iteration, augment dataset\n",
    "    if rho < data_aug - 1:\n",
    "        print(\"Augmenting substitute training data.\")\n",
    "        # Perform the Jacobian augmentation\n",
    "        lmbda_coef = 2 * int(int(rho / 3) != 0) - 1\n",
    "        X_sub = jacobian_augmentation(sess, x, X_sub, Y_sub, grads,\n",
    "                                      lmbda_coef * sub_lmbda)\n",
    "\n",
    "        print(\"Labeling substitute training data.\")\n",
    "        # Label the newly generated synthetic points using the black-box\n",
    "        Y_sub = np.hstack([Y_sub, Y_sub])\n",
    "        X_sub_prev = X_sub[int(len(X_sub)/2):]\n",
    "        eval_params = {'batch_size': sub_batch_size}\n",
    "        bbox_val = batch_eval(sess, [x], [bbox_preds], [X_sub_prev],\n",
    "                              args=eval_params)[0]\n",
    "        # Note here that we take the argmax because the adversary\n",
    "        # only has access to the label (not the probabilities) output\n",
    "        # by the black-box model\n",
    "        Y_sub[int(len(X_sub)/2):] = np.argmax(bbox_val, axis=1)\n",
    "            \n",
    "# Evaluate the substitute model on clean test examples\n",
    "eval_params = {'batch_size': sub_batch_size}\n",
    "acc = model_eval(sess, x, y, preds_sub, X_test, Y_test, args=eval_params)\n",
    "accuracies['sub'] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of oracle on adversarial examples generated using the substitute: 0.716040609137\n"
     ]
    }
   ],
   "source": [
    "# Wrap the FGSM attack object around the substitute model and evaluate it on the holdout data\n",
    "\n",
    "# Initialize the Fast Gradient Sign Method (FGSM) attack object.\n",
    "fgsm_par = {'eps': 0.3, 'ord': np.inf, 'clip_min': 0., 'clip_max': 1.}\n",
    "fgsm = FastGradientMethod(model_sub, sess=sess)\n",
    "\n",
    "# Craft adversarial examples using the substitute\n",
    "eval_params = {'batch_size': sub_batch_size}\n",
    "x_adv_sub = fgsm.generate(x, **fgsm_par)\n",
    "\n",
    "# Evaluate the accuracy of the \"black-box\" model on adversarial examples\n",
    "accuracy = model_eval(sess, x, y, model(x_adv_sub), X_test, Y_test,\n",
    "                      args=eval_params)\n",
    "print('Test accuracy of oracle on adversarial examples generated '\n",
    "      'using the substitute: ' + str(accuracy))\n",
    "accuracies['bbox_on_sub_adv_ex'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bbox_on_sub_adv_ex': 0.71604060913705581, 'sub': 0.76730964467005081, 'bbox': 0.98923857868020304}\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
